<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>fragment archive</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="styles.css" />
</head>
<body>

<!--    <div class="filter-container">
        <label for="category-filter">Filter by Category:</label>
        <select id="category-filter">
            <option value="all">All</option>
            <option value="category1">Category 1</option>
            <option value="category2">Category 2</option>
            <option value="category3">Category 3</option>
        </select>
    </div>-->

    <div class="container">
        <div class="content">
            <p> 
                Current web archiving initiatives are curated by state-affiliated organisations with selection bias 
                against low culture. Digital preservation is a losing battle - what gains are made by archiving collectives
                 are quickly closed up by technocapitalist policy. Additionally, preservation web crawling at scale is 
                 unable to capture the complex and dynamic web technologies that low media is often hosted on - this 
                 content is gated, transient and amorphously located. A two-birds-one-stone approach could be to 
                 encourage the individual amateur creation of personal archives, utilising open source preservation tools. 
                 Targeted amateur web archivists can scrape corners of the internet large crawls canâ€™t reach - or 
                 get around technological limitations with bespoke/guerilla archiving methods, preserving small-sample 
                 collections to garner a more representative historical record of internet topology. Like keeping pages of 
                 diaries instead of trying for the whole library. 
                </p>
            <a href="/crawl.html">How do I do this ?</a>
        </div>

    <div class="sidebar">
        <p>fragment archive</p>
        <p>persistently archived web emphemera collected 2022 - ongoing</p>
        <br />
        <a href="/index.html">home</a>
        <br />
        <a href="/manifesto.html">manifesto</a>
        <br />
        <a href="/info.html">info</a>
        <br />
        <a href="/crawl.html">tech</a>
        <br />
        <a href="/add.html">submit</a>
        <br />
        <a href="/more.html">more</a>
        <!-- <a href="https://rosemlondon.github.io/stones/" target="_blank">
            <iframe 
                src="https://rosemlondon.github.io/stones/" 
                style="width: 100%; height: 200px; border: none;">
            </iframe>
        </a> -->
    </div>

</body>
</html>